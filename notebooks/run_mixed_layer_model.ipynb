{
 "cells": [
  {
   "cell_type": "code",
   "id": "7efb8836",
   "metadata": {},
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "sys.path.append('../src/')\n",
    "from Biologging_Toolkit.applications.Mixed_Layer_Depth import MixedLayerDepth\n",
    "from Biologging_Toolkit.processing.Dives import Dives\n",
    "from Biologging_Toolkit.utils.format_utils import get_start_time_sens\n",
    "from Biologging_Toolkit.utils.inertial_utils import coa\n",
    "from Biologging_Toolkit.applications.Wind import Wind\n",
    "from Biologging_Toolkit.utils.plot_utils import subplots_centered\n",
    "from Biologging_Toolkit.models.MLD_Model import MLDModel\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import find_peaks, medfilt\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import generic_filter\n",
    "from scipy import odr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,                # Enable LaTeX text rendering\n",
    "    \"font.family\": \"serif\",             # Use a serif font\n",
    "    \"font.serif\": [\"Computer Modern\"],  # Set font to Computer Modern (LaTeX default)\n",
    "})\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "import seaborn as sns\n",
    "def norm(x) :\n",
    "    return (x - np.nanmin(x)) / (np.nanmax(x) - np.nanmin(x))\n",
    "import umap\n",
    "import hdbscan\n",
    "import sklearn.cluster as cluster\n",
    "import importlib"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3a5dd134-8d86-4573-b1a2-d58eb43d0dde",
   "metadata": {},
   "source": [
    "depids = ['ml18_296a','ml18_294b','ml19_292a','ml19_292b','ml19_293a','ml19_294a','ml20_293a','ml20_296b','ml20_313a','ml21_295a','ml21_305b','ml17_280a']\n",
    "#path = '/run/media/grosmaan/LaCie/individus_brut/individus/'\n",
    "path = 'D:/individus_brut/individus/'\n",
    "paths = [os.path.join(path, depid) for depid in depids]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f7a739f0-b53c-402d-a179-ef15dc99a8ce",
   "metadata": {},
   "source": [
    "corrected_mld = True\n",
    "depids_with_mld = []\n",
    "for depid in depids :\n",
    "    df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "    try :\n",
    "        if np.all(np.isnan(df.meop_mld.to_numpy())):\n",
    "            continue\n",
    "        depids_with_mld.append(depid)\n",
    "    except AttributeError:\n",
    "        continue\n",
    "if corrected_mld :\n",
    "    depids_with_mld = []\n",
    "    for depid in depids :\n",
    "        df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "        if 'corr_mld' in list(df.columns) :\n",
    "            depids_with_mld.append(depid)\n",
    "print(depids_with_mld)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "params = ['wind', 'temp', 'density', 'gradient', 'hour', 'lat', 'lon', 'depid_id']\n",
    "mae, r2 = [], []\n",
    "coeffs = []"
   ],
   "id": "4293945805740f9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = MLDModel(path, depids_with_mld,\n",
    "                 test_depid=depid, params=params,\n",
    "                 norm = False,\n",
    "                 deepening = True,\n",
    "                 target='mld')"
   ],
   "id": "6b4a3d7463434378",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.construct_2D_structure(t0 = 0, t1 = 24, size = 100, filter = 1)",
   "id": "2b0be290c1acf030",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(paths[5]+ f'/{depids[5]}_dive.csv')\n",
    "if norm:\n",
    "    norm = lambda x: (x - np.nanmin(x)) / (np.nanmax(x) - np.nanmin(x))\n",
    "else:\n",
    "    norm = lambda x: x\n",
    "timeframe, mld = df.begin_time.to_numpy(), df.meop_mld.to_numpy()\n",
    "temp, wind, gradient, density = norm(df.temp10m.to_numpy()), norm(df['lstm'].to_numpy()), norm(df.gradient.to_numpy()), norm(df.density10m.to_numpy())\n",
    "lat, lon = df.lat.to_numpy(), df.lon.to_numpy()\n",
    "mld[mld > np.quantile(mld, 0.99)] = np.nan\n",
    "wind_data, temp_data, gradient_data, density_data, previous_mld = [], [], [], [], []\n",
    "lat_data, lon_data, time_data = [], [], []\n",
    "for i in range(len(mld)):\n",
    "    low_bound = (timeframe >= timeframe[i] - 15 * 3600)\n",
    "    high_bound = (timeframe <= timeframe[i] - 0 * 3600)\n",
    "    _time = timeframe[low_bound & high_bound]\n",
    "    _mld = mld[low_bound & high_bound]\n",
    "    previous_mld.append(_mld[0] if (~np.all(low_bound) and len(_mld) != 0) else np.nan)\n",
    "    _wind = median_filter(wind[low_bound & high_bound], size=1, mode='nearest')\n",
    "    wind_data.append(interp1d(_time, _wind)(np.linspace(_time[0], _time[-1], 40)) if len(_wind) != 0\n",
    "                     else np.full(40, np.nan))\n",
    "    _temp = median_filter(temp[low_bound & high_bound], size=1, mode='nearest')\n",
    "    temp_data.append(interp1d(_time, _temp)(np.linspace(_time[0], _time[-1], 40)) if len(_temp) != 0\n",
    "                     else np.full(40, np.nan))\n",
    "    _density = median_filter(density[low_bound & high_bound], size=1, mode='nearest')\n",
    "    density_data.append(interp1d(_time, _density)(np.linspace(_time[0], _time[-1], 40)) if len(_density) != 0\n",
    "                        else np.full(40, np.nan))\n",
    "    _gradient = median_filter(gradient[low_bound & high_bound], size=1, mode='nearest')\n",
    "    gradient_data.append(interp1d(_time, _gradient)(np.linspace(_time[0], _time[-1], 40)) if len(_gradient) != 0\n",
    "                         else np.full(40, np.nan))\n",
    "    _lat = lat[low_bound & high_bound]\n",
    "    lat_data.append(interp1d(_time, _lat)(np.linspace(_time[0], _time[-1], 40)) if len(_temp) != 0\n",
    "                     else np.full(40, np.nan))\n",
    "    _lon = lon[low_bound & high_bound]\n",
    "    lon_data.append(interp1d(_time, _lon)(np.linspace(_time[0], _time[-1], 40)) if len(_temp) != 0\n",
    "                     else np.full(40, np.nan))\n",
    "    time_data.append(np.linspace(_time[0], _time[-1], 40))\n"
   ],
   "id": "5b0e7b3e0eb9352a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wind = model.data['wind'][:,20]\n",
    "mld = model.data['mld']\n",
    "temp = model.data['temp']\n",
    "density = model.data['density']\n",
    "gradient = model.data['gradient']\n",
    "def coa(lat, lon):\n",
    "\treturn np.sin(lat[1])*np.sin(lat[0]) + np.cos(lat[0])*np.cos(lat[1])*(np.cos((lon[1]-lon[0])))\n",
    "distance = [coa(model.data['lat'][i:i+2, 20], model.data['lon'][i:i+2,20]) for i in range(len(model.data['lat'])-1)]\n",
    "for i in range(0, len(mld), 5):\n",
    "    plt.scatter(np.sum(distance[i:i+20]), np.corrcoef(mld[i:i+20], wind[i:i+2:20])[0,1])"
   ],
   "id": "a43085e8ce9e5212",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b77542d85fba574e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "coa([40, 44], [3,5])",
   "id": "d4887de1e974682c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.data['lat'][40:42, 20]",
   "id": "eba389d624031073",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors = [\"b\", \"#ff7f0e\", \"g\", \"r\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"c\", \"k\", \"y\", \"m\", \"#1e90ff\", \"#008080\"]\n",
    "fig, ax = plt.subplots(1,2)\n",
    "for j, depid in enumerate(depids_with_mld):\n",
    "    model = MLDModel(path, [depid],\n",
    "                     test_depid=depid, params=params,\n",
    "                     deepening = True,\n",
    "                     target='mld')\n",
    "    model.construct_2D_structure(t0 = 0, t1 = 24, size = 60, filter = 1)\n",
    "    mld = model.data['mld']\n",
    "    for i in range(60) :\n",
    "        wind = model.data['wind'][:,i]\n",
    "        ax[0].scatter(i, np.corrcoef(wind[~np.isnan(wind) & ~np.isnan(mld)], mld[~np.isnan(wind) & ~np.isnan(mld)])[0,1], c = colors[j])\n",
    "    ax[1].plot(np.sort(np.sort(model.data['wind'][:,0])), c = colors[j])"
   ],
   "id": "5dfbb2beda7bcbf0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "59743f46a7921a19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (15,8))\n",
    "k = 312\n",
    "ax1 = ax[0].twinx()\n",
    "ax2 = ax[1].twinx()\n",
    "ax[0].plot(np.array(time_data)[k,:], np.array(wind_data)[k,:])\n",
    "ax1.scatter(np.array(time_data)[k, -1], np.array(mld[k]), c = 'orange')\n",
    "ax[1].plot(df.begin_time[df.begin_time<np.array(time_data)[k+1, -1]][-50:], df['lstm'][df.begin_time<np.array(time_data)[k+1, -1]][-50:])\n",
    "ax2.scatter(df.begin_time[df.begin_time<np.array(time_data)[k+1, -1]].iloc[-1], df['meop_mld'][df.begin_time<np.array(time_data)[k+1, -1]].iloc[-1], c = 'red')\n",
    "fig.show()"
   ],
   "id": "9405066fe4a23c3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ground_truth, preds = [],[]\n",
    "for depid in depids_with_mld :\n",
    "    model.test_depid = depid\n",
    "    model.neural_network(model_type = 'CNN_LSTM', input_size = 175, learning_rate = 0.0001, nepoch = 15)\n",
    "    preds.extend(model.neural_network_estimation)\n",
    "    ground_truth.extend(model.ground_truth)\n"
   ],
   "id": "4cd115bab75a400f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame({'preds':preds, 'gt':ground_truth})\n",
    "sns.kdeplot(df, x = 'preds', y = 'gt')\n",
    "#plt.scatter(preds, ground_truth)"
   ],
   "id": "23419ce4bdf855ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "df = pd.DataFrame({\"estimations\":np.array(preds).flatten(),\n",
    "                   \"target\":ground_truth,\n",
    "                   'time' :np.linspace(0,1,len(ground_truth))})\n",
    "df = df.melt(id_vars = 'time')\n",
    "px.line(df, y = 'value', x = 'time', color = \"variable\")"
   ],
   "id": "d0b998a9f4baadb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(model.data['mld_diff'], bins = 100)\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.linspace(-500,500,1000), np.tanh(np.linspace(-500,500,1000)/20)**2, c = 'orange')\n",
    "ax.set_xlim(-1,200)"
   ],
   "id": "af93ebe152c449b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def hour(x) :\n",
    "    result = []\n",
    "    for elem in x :\n",
    "        result.append(datetime.fromtimestamp(elem).hour)\n",
    "    return np.array(result)\n",
    "plt.scatter(hour(model.data['time']), model.data['mld_diff'],\n",
    "            c = np.nanmax(model.data['wind'], axis = 1), s = 1)\n",
    "df = pd.DataFrame({'time': hour(model.data['time']), 'mld_diff': model.data['mld_diff']})\n",
    "sns.boxplot(x=\"time\", y=\"mld_diff\",\n",
    "            data=df)\n",
    "plt.ylim(-20,20)"
   ],
   "id": "1a97cb232087273c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hour(model.data['time'])",
   "id": "a0b441681e3edfec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "df = pd.DataFrame({'target':ground_truth, 'estimations':preds})\n",
    "sns.kdeplot(df,\n",
    "            x = 'target',\n",
    "            y = 'estimations',\n",
    "            ax = ax)\n",
    "ax.plot([-200,200], [-200,200], '--', c = 'k')\n",
    "ax.set_xlim([-200,200])\n",
    "ax.set_ylim([-200,200])"
   ],
   "id": "c1454cd352cd9820",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_profiles(df, data = 'lstm', t0 = 10, t1 = 25, filter=1, norm = True) :\n",
    "    if norm :\n",
    "        norm = lambda x : (x - np.nanmin(x)) / (np.nanmax(x) - np.nanmin(x))\n",
    "    else :\n",
    "        norm = lambda x : x\n",
    "    timeframe = df.begin_time.to_numpy()\n",
    "    mld = df.meop_mld.to_numpy()\n",
    "    mld[mld > np.quantile(mld, 0.99)] = np.nan\n",
    "    temp = norm(df.temp10m.to_numpy())\n",
    "    wind = norm(df[data].to_numpy())\n",
    "    gradient = norm(df.gradient.to_numpy())\n",
    "    density = norm(df.density10m.to_numpy())\n",
    "    wind_data, temp_data, previous_mld, gradient_data, density_data = [], [], [], [], []\n",
    "    for i in range(len(mld)) :\n",
    "        low_bound = (timeframe >= timeframe[i] - t1*3600)\n",
    "        high_bound = (timeframe <= timeframe[i] - t0*3600)\n",
    "        _time = timeframe[low_bound & high_bound]\n",
    "        _mld = mld[low_bound & high_bound]\n",
    "        #previous_mld.append([_mld[int((low_bound & high_bound).sum()/2)]]*40 if len(_mld) != 0 else [np.nan]*40)\n",
    "        previous_mld.append(_mld[0])\n",
    "        _wind = median_filter(wind[low_bound & high_bound], size=filter, mode = 'nearest')\n",
    "        wind_data.append(interp1d(_time, _wind)(np.linspace(_time[0], _time[-1], 40)) if len(_wind)!=0\n",
    "                         else np.full(40,np.nan))\n",
    "        _temp = median_filter(temp[low_bound & high_bound], size=filter, mode = 'nearest')\n",
    "        temp_data.append(interp1d(_time, _temp)(np.linspace(_time[0], _time[-1], 40)) if len(_temp)!=0\n",
    "                         else np.full(40,np.nan))\n",
    "        _density = median_filter(density[low_bound & high_bound], size=filter, mode = 'nearest')\n",
    "        density_data.append(interp1d(_time, _density)(np.linspace(_time[0], _time[-1], 40)) if len(_density) != 0\n",
    "                            else np.full(40,np.nan))\n",
    "        _gradient = median_filter(gradient[low_bound & high_bound], size=filter, mode = 'nearest')\n",
    "        gradient_data.append(interp1d(_time, _gradient)(np.linspace(_time[0], _time[-1], 40)) if len(_gradient) != 0\n",
    "                             else np.full(40,np.nan))\n",
    "    return mld, previous_mld, wind_data, temp_data, density_data, gradient_data"
   ],
   "id": "4312cf982cd9dbdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mld, wind, temp, previous_mld, gradient, density = [],[],[],[],[],[]\n",
    "depid_data = []\n",
    "for i, depid in enumerate(depids_with_mld) :\n",
    "    _df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "    _mld, _previous_mld, _wind, _temp, _density, _gradient = get_profiles(_df, t0=0, t1=30, filter = 5, norm = True)\n",
    "    mld.extend(_mld)\n",
    "    wind.extend(_wind)\n",
    "    temp.extend(_temp)\n",
    "    depid_data.extend([depid]*len(_wind))\n",
    "    previous_mld.extend(_previous_mld)\n",
    "    gradient.extend(_gradient)\n",
    "    density.extend(_density)"
   ],
   "id": "71adc7a639c40967",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(data[:,41])\n",
    "plt.plot(model.X[:,81])\n",
    "plt.plot(np.arange(len(model.X), len(model.X)+len(model.x_test),1), model.x_test[:,81])"
   ],
   "id": "2640766125adc15a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(target)\n",
    "plt.plot(model.Y)\n",
    "plt.plot(np.arange(len(model.X), len(model.X)+len(model.x_test),1), model.y_test)"
   ],
   "id": "2d5e1d74182a4a84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mld = np.array(mld)\n",
    "depid_data = np.array(depid_data)\n",
    "previous_mld = np.array(previous_mld)\n",
    "wind = np.array(wind)\n",
    "temp = np.array(temp)\n",
    "density = np.array(density)\n",
    "gradient = np.array(gradient)\n",
    "data = np.hstack((wind, temp, gradient))\n",
    "target = mld - previous_mld\n",
    "data = np.nan_to_num(data)"
   ],
   "id": "932edb3451586dbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn, utils\n",
    "import torch\n",
    "model_MLP = nn.Sequential(\n",
    "    nn.Linear(200, 512),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(256, 1)\n",
    ")\n",
    "class LoadData(utils.data.Dataset) :\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.Y = torch.FloatTensor(Y)\n",
    "    def __len__(self) :\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx) :\n",
    "        return self.X[idx], self.Y[idx]\n",
    "estimations, labels_r = [], []\n",
    "'''data = data[~np.isnan(target)]\n",
    "depid_data = depid_data[~np.isnan(target)]\n",
    "target = target[~np.isnan(target)]'''\n",
    "losses = []\n",
    "for depid in depids_with_mld :\n",
    "\n",
    "    #X, Y = data[depid_data != depid], target[depid_data != depid]\n",
    "    #xtest, ytest = data[depid_data == depid], target[depid_data == depid]\n",
    "    model.test_depid = depid\n",
    "    model.multilayer_perceptron(nepoch = 0)\n",
    "    X = model.X\n",
    "    Y = model.Y\n",
    "    xtest, ytest = model.x_test, model.y_test\n",
    "    trainloader = utils.data.DataLoader(LoadData(X,Y), 32, shuffle = True)\n",
    "    testloader = utils.data.DataLoader(LoadData(xtest,ytest), 32, shuffle = False)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model_MLP.parameters(), lr=0.001, weight_decay = 0)\n",
    "    for epoch in range(1,16) :\n",
    "        for batch in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            input, labels = batch\n",
    "            outputs = model_MLP(input)\n",
    "            loss = criterion(outputs.squeeze(dim = 1), labels)\n",
    "            loss.backward()\n",
    "            if epoch == 1:\n",
    "                losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "        if epoch == 15 :\n",
    "            model_MLP.eval()\n",
    "            for batch in testloader:\n",
    "                input, labels = batch\n",
    "                outputs = model_MLP(input)\n",
    "                estimations.extend(outputs.detach().numpy().flatten())\n",
    "                labels_r.extend(labels)\n",
    "            model_MLP.train()\n",
    "    del optimizer, criterion\n",
    "estimations = np.array(estimations)\n",
    "labels = np.array(labels_r)"
   ],
   "id": "208843805e699390",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.plot(losses)",
   "id": "83a52776126d88b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "df = pd.DataFrame({'target':labels, 'estimations':np.array(estimations).flatten()})\n",
    "sns.kdeplot(df,\n",
    "            x = 'target',\n",
    "            y = 'estimations',\n",
    "            ax = ax)\n",
    "ax.plot([-200,200], [-200,200], '--', c = 'k')\n",
    "ax.set_xlim([-200,200])\n",
    "ax.set_ylim([-200,200])"
   ],
   "id": "f2dc0dff340fe012",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.scatter(ytest, estimations[-2309:], s = 1, alpha = 0.2)",
   "id": "b6c648271de437a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "df = pd.DataFrame({\"estimations\":np.array(estimations).flatten(),\n",
    "                   \"target\":target.flatten(),\n",
    "                   'time' :np.linspace(0,1,len(target))})\n",
    "df = df.melt(id_vars = 'time')\n",
    "px.line(df, y = 'value', x = 'time', color = \"variable\")"
   ],
   "id": "20aaa322353ed5ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(np.corrcoef(target.flatten(),np.array(estimations).flatten()))\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(target, estimations))"
   ],
   "id": "bb4ad64615ada53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame({'estimations':estimations,'target':target,'depid_data':depid_data, \"error\":estimations-target})\n",
    "sns.boxplot(x=\"depid_data\", y=\"error\",\n",
    "            data=df)"
   ],
   "id": "48dfee6b5acace3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for depid in depids_with_mld :\n",
    "    print(depid)\n",
    "    print('MAE : ', np.mean(abs(target-estimations)[depid_data==depid]))\n",
    "    print('RMAE : ', np.mean(abs(target-estimations)[depid_data==depid])/np.mean(abs(target[depid_data==depid])))"
   ],
   "id": "ed4350e8e8c64616",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(data), len(estimations)",
   "id": "d351f96b3af4b1ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.scatter(np.nanmean(data[:, 40:80], axis = 1), estimations-target)",
   "id": "a739c41bed39e2c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.nanvar(data[40:80], axis = 0)",
   "id": "bb23e502fe8b0608",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(data)"
   ],
   "id": "6c4c4a918f5ee62e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ccefb726-0477-4eae-ad47-9e5b6d6fb56e",
   "metadata": {},
   "source": [
    "#clus = cluster.KMeans(n_clusters=6).fit(data)\n",
    "#labels = clus.labels_\n",
    "labels = hdbscan.HDBSCAN(min_samples = 100, min_cluster_size = 1000).fit_predict(data)\n",
    "fig, ax = plt.subplots(figsize = (15,8))\n",
    "unique_labels = np.unique(labels)\n",
    "c = np.array(['darkorchid', 'indianred', 'cyan', 'orange', 'midnightblue', 'seagreen', 'salmon', 'gold'])\n",
    "c =  np.append(c[:len(unique_labels)], 'grey')\n",
    "colors = [c[label] for label in labels]\n",
    "ax.scatter(embedding[:,0], embedding[:,1], c = colors, s = 4)\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    ax.scatter([], [], label=f'Cluster {label}', color=c[label])\n",
    "ax.legend()\n",
    "'''label = [-1,0,3,5]\n",
    "#df = pd.DataFrame({'data':data[np.isin(labels,label)][:, 0], 'mld':mld[np.isin(labels,label)].flatten()})\n",
    "df = pd.DataFrame({'data':np.nanmax(data[:,:wind.shape[1]], axis = 1)[np.isin(labels,label)], 'mld':mld[np.isin(labels,label)].flatten()})\n",
    "sns.kdeplot(df, x = 'data', y = 'mld', ax = ax[1])\n",
    "ax[0].legend()'''"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1,2,figsize = (10, 6))\n",
    "ax[0].scatter(embedding[:,0], embedding[:,1], c = np.nanmax(temp, axis = 1), cmap = 'viridis_r', s = 4)\n",
    "ax[1].scatter(embedding[:,0], embedding[:,1], c = labels, s = 4, cmap = 'viridis')"
   ],
   "id": "ece37440eada8e30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame({'mld':target, 'wind':np.nanmax(wind, axis = 1), 'temp':labels})\n",
    "fig, ax = plt.subplots(2,2, sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for label in np.unique(labels):\n",
    "    df = pd.DataFrame({'mld':target[labels == label], 'wind':np.nanmax(wind, axis = 1)[labels == label]})\n",
    "    sns.kdeplot(df, x = 'wind', y = 'mld', ax = ax[label+1])"
   ],
   "id": "df470e3ef95c8cdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pygam import LinearGAM, GAM\n",
    "#data = data[np.isin(labels, [-1,0,2])]\n",
    "'''target = target[np.isin(labels, [-1,1,2,3])]\n",
    "data = data[np.isin(labels, [-1,1,2,3])]\n",
    "depid_data = depid_data[np.isin(labels, [-1,1,2,3])]\n",
    "data = data[~np.isnan(target)]\n",
    "depid_data = depid_data[~np.isnan(target)]\n",
    "target = target[~np.isnan(target)]\n",
    "target -= np.nanmin(target)-1'''\n",
    "default = {'distribution':'poisson','link':'log'}\n",
    "estimations = []\n",
    "for depid in depids_with_mld :\n",
    "    X, Y = data[depid_data != depid], target[depid_data != depid]\n",
    "    xtest, ytest = data[depid_data == depid], target[depid_data == depid]\n",
    "    gam = GAM(link=default['link'], distribution=default['distribution']).fit(X, Y)\n",
    "    estimations.extend(gam.predict(xtest))"
   ],
   "id": "c6ca80a7a087cda1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "     np.nanmin(target)",
   "id": "9eaa76a147ea7a54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "target",
   "id": "1ac1281a9570ecb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.scatter(target, estimations, s = 4, alpha = 0.2)\n",
    "plt.ylim(0,600)"
   ],
   "id": "ab789f69e36e28d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fed43ff9-3c2e-41df-b066-d47a1757408d",
   "metadata": {},
   "source": [
    "label = [-1,0,2]\n",
    "target = np.nan_to_num(target)\n",
    "#data_mask = target > 0\n",
    "#target = mld\n",
    "temperature = np.nanmax(temp, axis = 1)\n",
    "temperature[temperature < 5] = 0\n",
    "temperature[temperature >= 5] = 1\n",
    "data = np.hstack((data, data**2, np.ones((len(data),1))))\n",
    "data = data[temperature == 1]\n",
    "labels = labels[temperature == 1]\n",
    "target = target[temperature == 1]\n",
    "x, residual, rank, s = np.linalg.lstsq(data[np.isin(labels, label)],  target[np.isin(labels, label)])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "#ax[0].scatter(mld[labels == label], data[labels == label] @ x, alpha = 0.1)\n",
    "df = pd.DataFrame({'pred': (data[np.isin(labels, label)] @ x).flatten(), 'target' : target.flatten()[np.isin(labels, label)]})\n",
    "'''temperature = np.nanmax(temp, axis = 1)[np.isin(labels, label)]\n",
    "temperature[temperature < 5] = 0\n",
    "temperature[temperature >= 5] = 1'''\n",
    "sns.kdeplot(df, x = 'target', y = 'pred', ax = ax)\n",
    "ax.plot([0, 200], [0, 200], '--', c = 'k')\n",
    "ax.set_xlim([-30, 300])\n",
    "ax.set_ylim([-30, 300])"
   ],
   "id": "3198c59d883b049d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.scatter(target.flatten()[np.isin(labels, label)], (data[np.isin(labels, label)] @ x).flatten() - target.flatten()[np.isin(labels, label)])",
   "id": "29e224fc09cab3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "mld.shape, wind.shape",
   "id": "67bd720f0d32e991",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ffbaf5d6-9b9b-46b4-b9f7-205eb844158e",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(1, 2, sharex = True, sharey = True, figsize = (15, 8))\n",
    "#ax[0].scatter(mld[labels == label], data[labels == label] @ x, alpha = 0.1)\n",
    "df = pd.DataFrame({'pred': (data[np.isin(labels, label)] @ x).flatten(), 'mld' : mld.flatten()[np.isin(labels, label)]})\n",
    "sns.kdeplot(df, x = 'mld', y = 'pred', ax = ax[0])\n",
    "print(np.nanmean(abs(df.pred.to_numpy() - df.mld.to_numpy())))\n",
    "df = pd.DataFrame({'pred':g(data[np.isin(labels, label)][:, 0], *popt), 'mld':mld.flatten()[np.isin(labels, label)]})\n",
    "sns.kdeplot(df, x = 'mld', y = 'pred', ax = ax[1])\n",
    "print(np.nanmean(abs(df.pred.to_numpy() - df.mld.to_numpy())))\n",
    "#ax[1].scatter(mld[labels == label], g(data[labels == label][:, 0], *popt), alpha = 0.1)\n",
    "ax[0].plot([0, 400], [0, 400], '--', c = 'k')\n",
    "ax[1].plot([0, 400], [0, 400], '--', c = 'k')\n",
    "ax[0].set_ylim(0, 300)\n",
    "ax[0].set_xlim(0, 300)\n",
    "ax[0].grid()\n",
    "ax[1].grid()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def g(x, a, b, c) :\n",
    "    return a*x**2 + b*x + c\n",
    "bounds = [[0,-np.inf, 0],[np.inf, np.inf, 50]]\n",
    "nan_mask = (~np.isnan(data[np.isin(labels,label)][:, 0]) & ~np.isnan(mld[np.isin(labels,label)].flatten()))\n",
    "temp_mask = temp[np.isin(labels,label)][:,0] < 8\n",
    "popt, _ = curve_fit(g, data[np.isin(labels,label)][:, 0][nan_mask & temp_mask], mld[np.isin(labels,label)].flatten()[nan_mask & temp_mask], bounds = bounds)\n",
    "plt.scatter(data[np.isin(labels,label)][:, 0][temp_mask], mld[np.isin(labels,label)][temp_mask].flatten(), s=5, alpha = 0.4, c = temp[np.isin(labels,label)][:, 0][temp_mask])\n",
    "plt.plot(list(range(0,20)), g(np.array(list(range(0,20))), *popt))"
   ],
   "id": "f9f5d514-955b-48b6-81ce-2c518ddfc01c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_wind_gust(df, data = 'lstm', t0 = 15, t1 = 25, sort = False) :\n",
    "    timeframe = df.begin_time.to_numpy()\n",
    "    mld = df.meop_mld.to_numpy()\n",
    "    temp = df.temp_10m.to_numpy()\n",
    "    wind = df[data].to_numpy()\n",
    "    wind_data = []\n",
    "    temp_data = []\n",
    "    previous_mld = []\n",
    "    for i in range(len(mld)) :\n",
    "        low_bound = (timeframe >= timeframe[i] - t1*3600)\n",
    "        high_bound = (timeframe <= timeframe[i] - t0*3600)\n",
    "        previous_mld.append(mld[low_bound][0])\n",
    "        _wind = wind[low_bound & high_bound]\n",
    "        _wind = _wind[~np.isnan(_wind)]\n",
    "        _temp = temp[low_bound & high_bound]\n",
    "        _temp = _temp[~np.isnan(_temp)]\n",
    "        if sort :\n",
    "            _wind = np.sort(_wind)[::-1]\n",
    "        wind_data.append(list(_wind))\n",
    "        temp_data.append(list(_temp))\n",
    "    return mld, previous_mld, wind_data, temp_data"
   ],
   "id": "38cbca9a-8c4c-4976-86cf-267becd4db23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mld, wind, temp, previous_mld = [],[],[], []\n",
    "for i, depid in enumerate(depids_with_mld) :\n",
    "    _df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "    _mld, _previous_mld, _wind, _temp, _density, _gradient = get_profiles(_df, t0=8, t1=30, sort = True)\n",
    "    mld.extend(_mld)\n",
    "    wind.extend(_wind)\n",
    "    temp.extend(_temp)\n",
    "    previous_mld.extend(_previous_mld)\n",
    "max_wind = max(len(seq) for seq in wind)\n",
    "wind = np.array([seq + [np.nan] * (max_wind - len(seq)) for seq in wind])\n",
    "max_temp = max(len(seq) for seq in temp)\n",
    "temp = np.array([seq + [np.nan] * (max_temp - len(seq)) for seq in temp])\n",
    "mld = np.vstack(mld)\n",
    "wind = np.vstack(wind)\n",
    "temp = np.vstack(temp)\n",
    "previous_mld = np.array(previous_mld)\n",
    "\n",
    "data = np.column_stack((wind, temp))\n",
    "target = mld - previous_mld[:,0]\n",
    "#data = wind"
   ],
   "id": "8a51804f-8fc5-496a-b350-f0b4e1402866",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "97340f647b55a3eb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
