{
 "cells": [
  {
   "cell_type": "code",
   "id": "7efb8836",
   "metadata": {},
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "sys.path.append('../src/')\n",
    "from Biologging_Toolkit.applications.Mixed_Layer_Depth import MixedLayerDepth\n",
    "from Biologging_Toolkit.processing.Dives import Dives\n",
    "from Biologging_Toolkit.utils.format_utils import get_start_time_sens"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e5a80c0",
   "metadata": {},
   "source": [
    "depid = 'ml18_294b'\n",
    "path = os.path.join('D:/individus_brut/individus/', depid)\n",
    "ref_path = os.path.join(path, 'data', 'auxiliary', 'instrument')\n",
    "sens_path = os.path.join(ref_path, depid+'sens5.nc')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4826a837",
   "metadata": {},
   "source": [
    "### Make sure csv structure for dive data exists"
   ]
  },
  {
   "cell_type": "code",
   "id": "46088c24-d17b-42fe-9b39-4749e5a599c6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dive = Dives(depid, path = ref_path, sens_path = sens_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "95c415e0-ee3d-439d-a0ee-000097000615",
   "metadata": {},
   "source": [
    "dive()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc97121f-1cdf-4419-8b1d-12ebd01a08b6",
   "metadata": {},
   "source": [
    "### Add temperature data to reference structure"
   ]
  },
  {
   "cell_type": "code",
   "id": "0af0343c-978d-4b55-8381-db89af8499dd",
   "metadata": {},
   "source": [
    "ds = nc.Dataset(sens_path)\n",
    "temperature = ds['T'][:].data\n",
    "temp_time = get_start_time_sens(ds.dephist_device_datetime_start) + np.arange(0, len(temperature))/5"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f34026a1-6af5-4d0a-be34-fe300aecd7c6",
   "metadata": {},
   "source": [
    "dive.create_variable('temperature',\n",
    "                     var_data =  temperature,\n",
    "                     var_time = temp_time)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4797234e-d67a-41c8-a170-aae2b0249dea",
   "metadata": {},
   "source": [
    "dive.ds"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2345b465-f9a4-443c-b1f3-0868c64cf835",
   "metadata": {},
   "source": [
    "dive.ds.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "78233d31-8f6b-4a08-b152-352ad61c43ea",
   "metadata": {},
   "source": [
    "### Compute mixed layer depth"
   ]
  },
  {
   "cell_type": "code",
   "id": "9806676f",
   "metadata": {},
   "source": [
    "inst = MixedLayerDepth(depid, \n",
    "            path = ref_path\n",
    "           )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e54a5d2f",
   "metadata": {},
   "source": [
    "inst()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bf516cab-69fe-4443-b624-56aed17df99d",
   "metadata": {},
   "source": [
    "### Wind correlation with MLD"
   ]
  },
  {
   "cell_type": "code",
   "id": "3a5dd134-8d86-4573-b1a2-d58eb43d0dde",
   "metadata": {},
   "source": [
    "depids = ['ml18_296a','ml18_294b','ml19_292a','ml19_292b','ml19_293a','ml19_294a','ml20_293a','ml20_296b','ml20_313a','ml21_295a','ml21_305b','ml17_280a']\n",
    "#path = '/run/media/grosmaan/LaCie/individus_brut/individus/'\n",
    "path = 'D:/individus_brut/individus/'\n",
    "paths = [os.path.join(path, depid) for depid in depids]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0f6d739b-70e1-4df8-9a38-48c023e31ffb",
   "metadata": {},
   "source": [
    "from Biologging_Toolkit.applications.Wind import Wind\n",
    "from Biologging_Toolkit.utils.plot_utils import subplots_centered\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,                # Enable LaTeX text rendering\n",
    "    \"font.family\": \"serif\",             # Use a serif font\n",
    "    \"font.serif\": [\"Computer Modern\"],  # Set font to Computer Modern (LaTeX default)\n",
    "})\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f7a739f0-b53c-402d-a179-ef15dc99a8ce",
   "metadata": {},
   "source": [
    "corrected_mld = False\n",
    "depids_with_mld = []\n",
    "for depid in depids :\n",
    "    df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "    try :\n",
    "        if np.all(np.isnan(df.meop_mld.to_numpy())):\n",
    "            continue\n",
    "        depids_with_mld.append(depid)\n",
    "    except AttributeError:\n",
    "        continue\n",
    "if corrected_mld :\n",
    "    depids_with_mld = []\n",
    "    for depid in depids :\n",
    "        df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "        if 'corr_mld' in list(df.columns) :\n",
    "            depids_with_mld.append(depid)\n",
    "print(depids_with_mld)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4631a41-c2d9-43a5-b819-4552c258dc74",
   "metadata": {},
   "source": [
    "def get_previous_wind_single(df, data, groupby = 'FOD') :\n",
    "    wind_interp = interp1d(df.end_time, df[data], bounds_error = False)\n",
    "    for i in range(48):\n",
    "        df[f'wind_{i}h'] = wind_interp(df.end_time - i*3600)\n",
    "    if groupby :\n",
    "        data = ['meop_mld', groupby]\n",
    "    else :\n",
    "        data = ['meop_mld']\n",
    "    for i in range(48):\n",
    "        data.append(f'wind_{i}h')\n",
    "    return df[data]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b370482-2b2a-4081-bf6e-4454c7274072",
   "metadata": {},
   "source": [
    "def get_previous_wind(df, data) :\n",
    "    wind_interp = interp1d(df.end_time, df.wind_speed, bounds_error = False)\n",
    "    pensieri_interp = interp1d(df.end_time, df.pensieri, bounds_error = False)\n",
    "    lstm_interp = interp1d(df.end_time, df.lstm, bounds_error = False)\n",
    "    hild_interp = interp1d(df.end_time, df.hildebrand, bounds_error = False)\n",
    "    for i in range(48):\n",
    "        df[f'wind_{i}h'] = wind_interp(df.end_time - i*3600)\n",
    "        df[f'pensieri_{i}h'] = pensieri_interp(df.end_time - i*3600)\n",
    "        df[f'lstm_{i}h'] = lstm_interp(df.end_time - i*3600)\n",
    "        df[f'hildebrand_{i}h'] = hild_interp(df.end_time - i*3600)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b337090-7abc-4bd0-9690-8c072500a23c",
   "metadata": {},
   "source": [
    "def get_correlation(depids, depid, path, data = 'downwards_mean_5000', FOD = 'FOD') :\n",
    "    df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "    inst = Wind(depids, path = paths, test_depid = depid, data = data)\n",
    "    inst.depid_fit()\n",
    "    est = inst.df[inst.df.depid == depid].depid_estimation.to_numpy()\n",
    "    df['pensieri'] = est\n",
    "    inst = Wind(depids, path = paths, test_depid = depid, data = data, method = 'Hildebrand')\n",
    "    inst.depid_fit()\n",
    "    est = inst.df[inst.df.depid == depid].depid_estimation.to_numpy()\n",
    "    df['hildebrand'] = est\n",
    "    df = get_previous_wind(df, data = data)\n",
    "    if FOD :\n",
    "        data_pens = ['meop_mld', FOD]; data_era = ['meop_mld', FOD]; data_lstm = ['meop_mld', FOD]; data_hild = ['meop_mld', FOD]\n",
    "    else :\n",
    "        data_pens = ['meop_mld']; data_era = ['meop_mld']; data_lstm = ['meop_mld']; data_hild = ['meop_mld']\n",
    "    for i in range(48):\n",
    "        data_pens.append(f'pensieri_{i}h')\n",
    "        data_era.append(f'wind_{i}h')\n",
    "        data_lstm.append(f'lstm_{i}h')\n",
    "        data_hild.append(f'hildebrand_{i}h')\n",
    "    return df[data_era], df[data_pens], df[data_lstm], df[data_hild]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "74937097-2ffc-4764-a32e-ebeeb7a4be05",
   "metadata": {},
   "source": [
    "#### HEATMAP FOR BINNED INDEPENDANT VARIABLE OF CORRELATION AS A FUNCTION OF WIND AVERAGING PERIOD AND HOURS BEFORE MLD\n",
    "colors = colormaps.get_cmap('plasma').resampled(5)\n",
    "FOD = True\n",
    "fod_labels = [1,2,3,4,5]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i, depid in enumerate(depids_with_mld) :\n",
    "    _df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "    _df = get_previous_wind_single(_df, 'lstm', groupby = 'temp_200m')\n",
    "    for avg in range(2, 25) :\n",
    "        _roll = _df.iloc[:, 2:50].rolling(avg, min_periods=1, center=True).mean()\n",
    "        _roll.columns = [f'avg{avg}_{col}' for col in list(_roll.columns)]\n",
    "        _df = pd.concat((_df, _roll), axis = 1)\n",
    "    df = pd.concat((df, _df))\n",
    "    \n",
    "temp_bins = [0, 3, 6, 12.5, float('inf')]\n",
    "mld_bins = [0, df['meop_mld'].quantile(0.33), df['meop_mld'].quantile(0.66), np.inf]\n",
    "temp_bins = [0, df['temp_200m'].quantile(0.25), df['temp_200m'].quantile(0.5), df['temp_200m'].quantile(0.75), np.inf]\n",
    "labels = [1, 2, 3, 4]\n",
    "df['bins'] = pd.cut(df['temp_200m'], bins=temp_bins, labels=labels, right=False)\n",
    "\n",
    "if FOD:\n",
    "    fig, ax = plt.subplots(2,2,figsize = (12, 12), sharey = True)\n",
    "    ax = ax.flatten()\n",
    "    for k in range(1, 5):\n",
    "        sns.heatmap(\n",
    "            df[df.bins == k].corr()['meop_mld'][2:-1].to_numpy().reshape(-1, 48), \n",
    "            ax=ax[k - 1],\n",
    "            cbar_kws={'label': 'Pearson correlation coefficient'}\n",
    "        )\n",
    "        ax[k-1].set_title(f'Bin {k}')\n",
    "else :\n",
    "    fig, ax = plt.subplots(figsize = (15, 10))\n",
    "    sns.heatmap(\n",
    "            df.corr()['meop_mld'][2:-1].to_numpy().reshape(-1, 48), \n",
    "            ax=ax,\n",
    "            cbar_kws={'label': 'Pearson correlation coefficient'}\n",
    "        )\n",
    "fig.text(0.5, 0.04, 'Hours before MLD obtention', ha='center', va='center', fontsize=14)\n",
    "fig.text(0.04, 0.5, 'Wind averaging period in hours', ha='center', va='center', rotation='vertical', fontsize=14)\n",
    "fig.tight_layout(rect=[0.05, 0.05, 1, 1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70fc205b-4679-4faa-a397-f9345b445bdc",
   "metadata": {},
   "source": [
    "fig.savefig('C:/Users/grosm/Desktop/thèse/Figures/wind_averaged_correlation_mld_all_SES.pdf')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "39d6a75b-8f05-496d-a90f-6aac47a1831f",
   "metadata": {},
   "source": [
    "### CORRELATION FOR EACH INDIVIDUAL AS A FUNCTION OF TIME DIFFERENTIAL AND FOR DIFFERENT MODELS\n",
    "\n",
    "fig, ax = subplots_centered(3,4,figsize = (20, 20), sharey = True, nfigs = 11)\n",
    "#fig1, ax1 = subplots_centered(3,2,figsize = (10, 10), sharey = True, nfigs = 5)\n",
    "colors = colormaps.get_cmap('plasma').resampled(5)\n",
    "FOD = False\n",
    "df_era = pd.DataFrame()\n",
    "df_lstm = pd.DataFrame()\n",
    "df_hild = pd.DataFrame()\n",
    "df_pens = pd.DataFrame()\n",
    "for i, depid in enumerate(depids_with_mld) :\n",
    "    fod_counts = np.array([0,0,0,0,0])\n",
    "    fod_labels = [1,2,3,4,5]\n",
    "    _df_era, _df_pens, _df_lstm, _df_hild = get_correlation(depids, depid, path, data = 'upwards_mean_5000', FOD = 'temp_200m')\n",
    "    df_era = pd.concat((df_era, _df_era))\n",
    "    df_lstm = pd.concat((df_lstm, _df_lstm))\n",
    "    df_pens = pd.concat((df_pens, _df_pens))\n",
    "    df_hild = pd.concat((df_hild, _df_hild))\n",
    "\n",
    "    #ax1[i].bar(fod_labels, fod_counts, align='center')\n",
    "    #ax1[i].set_title(depid)\n",
    "    #ax1[i].grid()\n",
    "    if FOD :\n",
    "        labels, counts = np.unique(_df_era.FOD, return_counts=True)\n",
    "        counts = counts[~np.isnan(labels)]\n",
    "        labels = labels[~np.isnan(labels)]\n",
    "        fod_counts[labels.astype(int)-1] = counts\n",
    "        for k in range(1,6) :\n",
    "            ax[i].plot(_df_era[_df_era.FOD == k].corr()['meop_mld'][2:].to_numpy(), color = colors(k-1), marker = 's')\n",
    "        #ax[i].plot(np.nanmean(np.column_stack([df_pens[df_pens.FOD == j].corr()['meop_mld'][2:] for j in range(1,2)]), axis = 1), color = colors(0), marker = '^')\n",
    "        #ax[i].plot(np.nanmean(np.column_stack([df_hild[df_hild.FOD == j].corr()['meop_mld'][2:] for j in range(1,2)]), axis = 1), color = colors(0), marker = 'P')\n",
    "        #ax[i].plot(np.nanmean(np.column_stack([df_lstm[df_lstm.FOD == j].corr()['meop_mld'][2:] for j in range(1,2)]), axis = 1), color = colors(2), marker = 'o')\n",
    "    else :\n",
    "        ax[i].plot(_df_era.corr()['meop_mld'].to_numpy()[2:], color = colors(3))\n",
    "        ax[i].plot(_df_pens.corr()['meop_mld'].to_numpy()[2:], color = colors(0))\n",
    "        ax[i].plot(_df_hild.corr()['meop_mld'].to_numpy()[2:], color = colors(1))\n",
    "        ax[i].plot(_df_lstm.corr()['meop_mld'].to_numpy()[2:], color = colors(2))\n",
    "    ax[i].grid()\n",
    "    ax[i].set_title(depid)\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color=colors(0), lw=2, label=\"Quadratic\"),\n",
    "    plt.Line2D([0], [0], color=colors(1), lw=2, label=\"Logarithmic\"),\n",
    "    plt.Line2D([0], [0], color=colors(2), lw=2, label=\"LSTM\"),\n",
    "    plt.Line2D([0], [0], color=colors(3), lw=2, label=\"ERA\"),\n",
    "    ]\n",
    "ax[0].legend(handles = legend_handles)\n",
    "ax[0].set_xticklabels([])\n",
    "ax[1].set_xticklabels([])\n",
    "ax[2].set_xticklabels([])\n",
    "#ax1[0].set_xticklabels([])\n",
    "#ax1[1].set_xticklabels([])\n",
    "#ax1[2].set_xticklabels([])\n",
    "fig.text(0.56, 0.04, 'Hours before MLD obtention', ha='center', va='center', fontsize=14)\n",
    "fig.text(0.04, 0.5, r'Pearson correlation coefficient with previous wind speeds and MLD', ha='center', va='center', rotation='vertical', fontsize=14)\n",
    "fig.tight_layout(rect=[0.05, 0.05, 1, 1])\n",
    "#fig1.text(0.56, 0.04, 'FOD', ha='center', va='center', fontsize=14)\n",
    "#fig1.text(0.04, 0.5, 'Number of occurences', ha='center', va='center', rotation='vertical', fontsize=14)\n",
    "#fig1.tight_layout(rect=[0.05, 0.05, 1, 1])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "09eeb324-d8a1-4f79-9399-3233f5a292a4",
   "metadata": {},
   "source": [
    "fig.savefig('C:/Users/grosm/Desktop/thèse/Figures/wind_mld_all_SES.pdf')\n",
    "#fig1.savefig('C:/Users/grosm/Desktop/thèse/Figures/FOD_histogram.pdf')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2c942a1-e109-4a20-8da5-754aabfd3e0b",
   "metadata": {},
   "source": [
    "### CORRELATION AVERAGED OVER INDIVIDUALS FOR DIFFERENT MODELS AND BINNED INDEPENDANT VARIABLE\n",
    "\n",
    "fig, ax = plt.subplots(3,2, figsize = (8,12), sharey = True)\n",
    "ax = ax.flatten()\n",
    "colors = colormaps.get_cmap('viridis').resampled(4)\n",
    "groupby = 'bins'\n",
    "if groupby == 'bins': \n",
    "    nbins = 6\n",
    "    nbins += 1\n",
    "    df_lstm['bins'] = pd.cut(df_lstm['temp_200m'], bins=np.linspace(-2, 15, nbins), labels = list(range(1,nbins)), right=False)\n",
    "    df_era['bins'] = pd.cut(df_era['temp_200m'], bins=np.linspace(-2, 15, nbins), labels = list(range(1,nbins)), right=False)\n",
    "    df_pens['bins'] = pd.cut(df_pens['temp_200m'], bins=np.linspace(-2, 15, nbins), labels = list(range(1,nbins)), right=False)\n",
    "    df_hild['bins'] = pd.cut(df_hild['temp_200m'], bins=np.linspace(-2, 15, nbins), labels = list(range(1,nbins)), right=False)\n",
    "for k in range(1,nbins) :\n",
    "    ax[k-1].set_title(f\"Temperature [{np.linspace(-2, 15, nbins)[k-1]}° : {np.linspace(-2, 15, nbins)[k]}°]\")\n",
    "    ax[k-1].grid()\n",
    "    ax[k-1].plot(df_era[df_era[groupby] == k].corr()['meop_mld'].to_numpy()[2:], color = colors(0), marker = 's', markevery=(0,5))\n",
    "    ax[k-1].plot(df_pens[df_pens[groupby] == k].corr()['meop_mld'].to_numpy()[2:], color = colors(1), marker = '^', markevery=(1,5))\n",
    "    ax[k-1].plot(df_hild[df_hild[groupby] == k].corr()['meop_mld'].to_numpy()[2:], color = colors(2), marker = 'P', markevery=(2,5))\n",
    "    ax[k-1].plot(df_lstm[df_lstm[groupby] == k].corr()['meop_mld'].to_numpy()[2:], color = colors(3), marker = 'o', markevery=(3,5))\n",
    "    ax[k-1].plot([np.nanargmax(df_era[df_era[groupby] == k].corr()['meop_mld'].to_numpy()[2:])]*10, \n",
    "                 np.linspace(0, np.nanmax(df_era[df_era[groupby] == k].corr()['meop_mld'].to_numpy()[2:]), 10),\n",
    "                 '--', color = colors(0))\n",
    "    ax[k-1].plot([np.nanargmax(df_pens[df_pens[groupby] == k].corr()['meop_mld'].to_numpy()[2:])]*10, \n",
    "             np.linspace(0, np.nanmax(df_pens[df_pens[groupby] == k].corr()['meop_mld'].to_numpy()[2:]), 10),\n",
    "             '--', color = colors(1))\n",
    "    ax[k-1].plot([np.nanargmax(df_hild[df_hild[groupby] == k].corr()['meop_mld'].to_numpy()[2:])]*10, \n",
    "                 np.linspace(0, np.nanmax(df_hild[df_hild[groupby] == k].corr()['meop_mld'].to_numpy()[2:]), 10),\n",
    "                 '--', color = colors(2))\n",
    "    ax[k-1].plot([np.nanargmax(df_lstm[df_lstm[groupby] == k].corr()['meop_mld'].to_numpy()[2:])]*10, \n",
    "                 np.linspace(0, np.nanmax(df_lstm[df_lstm[groupby] == k].corr()['meop_mld'].to_numpy()[2:]), 10),\n",
    "                 '--', color = colors(3))\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color=colors(0), lw=2, label=\"ERA5\"),\n",
    "    plt.Line2D([0], [0], color=colors(1), lw=2, label=\"Quadratic model\"),\n",
    "    plt.Line2D([0], [0], color=colors(2), lw=2, label=\"Logarithmic model\"),\n",
    "    plt.Line2D([0], [0], color=colors(3), lw=2, label=\"LSTM inertial\")\n",
    "    ]\n",
    "ax[0].legend(handles = legend_handles)\n",
    "fig.text(0.56, 0.04, 'Hours before MLD obtention', ha='center', va='center', fontsize=14)\n",
    "fig.text(0.04, 0.5, r'Pearson correlation coefficient with previous wind speeds and MLD', ha='center', va='center', rotation='vertical', fontsize=14)\n",
    "fig.tight_layout(rect=[0.05, 0.05, 1, 1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c47ba333-69fc-4e1b-b178-2dd8548c5c76",
   "metadata": {},
   "source": [
    "fig.savefig('C:/Users/grosm/Desktop/thèse/Figures/wind_mld_per_temperature_bin.pdf')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "758b0a1c-a6cc-456c-831e-0db7b6c466f2",
   "metadata": {},
   "source": [
    "#### GLOBAL CORRELATION AVERAGED OVER ALL ELEPHANT SEALS FOR DIFFERENT WIND MODELS\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (7,7))\n",
    "colors = colormaps.get_cmap('viridis').resampled(4)\n",
    "ax.set_title(f\"Correlation for all FODs\")\n",
    "ax.grid()\n",
    "ax.plot(df_era.corr()['meop_mld'].to_numpy()[2:-1], color = colors(0), marker = 's')\n",
    "ax.plot(df_pens.corr()['meop_mld'].to_numpy()[2:-1], color = colors(1), marker = '^')\n",
    "ax.plot(df_hild.corr()['meop_mld'].to_numpy()[2:-1], color = colors(2), marker = 'P')\n",
    "ax.plot(df_lstm.corr()['meop_mld'].to_numpy()[2:-1], color = colors(3), marker = 'o')\n",
    "legend_handles = [\n",
    "    plt.Line2D([0], [0], color=colors(0), lw=2, label=\"ERA5\"),\n",
    "    plt.Line2D([0], [0], color=colors(1), lw=2, label=\"Quadratic model\"),\n",
    "    plt.Line2D([0], [0], color=colors(2), lw=2, label=\"Logarithmic model\"),\n",
    "    plt.Line2D([0], [0], color=colors(3), lw=2, label=\"LSTM inertial\")\n",
    "    ]\n",
    "ax.legend(handles = legend_handles)\n",
    "fig.text(0.56, 0.04, 'Hours before MLD obtention', ha='center', va='center', fontsize=14)\n",
    "fig.text(0.04, 0.5, r'Pearson correlation coefficient with previous wind speeds and MLD', ha='center', va='center', rotation='vertical', fontsize=14)\n",
    "fig.tight_layout(rect=[0.05, 0.05, 1, 1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1dbfea61-0963-4c41-bbad-9988924075cc",
   "metadata": {},
   "source": [
    "fig.savefig('C:/Users/grosm/Desktop/thèse/Figures/global_correlation_SES_with_mld.pdf')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "033bc1ed-794e-4cae-8a8c-959280169e1d",
   "metadata": {},
   "source": [
    "### Wind vs. MLD"
   ]
  },
  {
   "cell_type": "code",
   "id": "6a227112-da78-4eda-90db-94b6dfb82ed9",
   "metadata": {},
   "source": [
    "depids = ['ml18_296a','ml18_294b','ml19_292a','ml19_292b','ml19_293a','ml19_294a','ml20_293a','ml20_296b','ml20_313a','ml21_295a','ml21_305b','ml17_280a']\n",
    "path = 'D:/individus_brut/individus/'\n",
    "paths = [os.path.join(path, depid) for depid in depids]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2a1a5e9-64f3-49eb-9414-dd01b7fd4114",
   "metadata": {},
   "source": [
    "from Biologging_Toolkit.applications.Wind import Wind\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,                # Enable LaTeX text rendering\n",
    "    \"font.family\": \"serif\",             # Use a serif font\n",
    "    \"font.serif\": [\"Computer Modern\"],  # Set font to Computer Modern (LaTeX default)\n",
    "})\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "41339bac-704e-4239-a06e-b975884f3d08",
   "metadata": {},
   "source": [
    "def get_previous_state(df, data, i) :\n",
    "    wind_interp = interp1d(df.end_time, df[data], bounds_error = False)\n",
    "    mld_interp = interp1d(df.end_time, df.meop_mld, bounds_error = False)\n",
    "    #df[f'{data}_{i}h'] = wind_interp(df.end_time - i*3600)\n",
    "    df[f'{data}_{i}h'] = wind_interp(df.end_time - i*3600)\n",
    "    df[f'mld_{i}h'] = mld_interp(df.end_time - i*3600)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "488de0b1-5bea-41bc-9516-d899a5c6de18",
   "metadata": {},
   "source": [
    "def get_corr_df(depids, depid, path, data = 'upwards_mean_5000', i = 15) :\n",
    "    df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "    '''inst = Wind(depids, path = paths, test_depid = depid, data = data)\n",
    "    inst.depid_fit()\n",
    "    est = inst.df[inst.df.depid == depid].depid_estimation.to_numpy()\n",
    "    df['temp_model'] = est'''\n",
    "    df = get_previous_state(df, data = 'lstm', i = i)\n",
    "    df['mld_variation'] = df.meop_mld - df[f'mld_{i}h']\n",
    "    df['wind_variation'] = df.lstm - df[f'lstm_{i}h']\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a9093c08-386b-47bf-8071-41acf59b575e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### SHOW MLD VARIATION AS A FUNCTION OF WIND SPEED FOR DIFFERENT FODs\n",
    "fig, ax = subplots_centered(3, 2, figsize = (13, 13), sharex = True, sharey = True, nfigs = 5)\n",
    "hour_fod = [47,10,35,22,11]\n",
    "FOD_df = pd.DataFrame()\n",
    "for fod in range(1,6) :\n",
    "    df = pd.DataFrame()\n",
    "    for j, depid in enumerate(['ml18_294b','ml19_292b','ml19_293a','ml19_294a','ml20_296b']) :\n",
    "        _df = get_corr_df(depids, depid, path, data = 'downwards_mean_5000', i = hour_fod[fod-1])\n",
    "        df = pd.concat((df, _df[['FOD', 'mld_variation', 'lstm', 'max_depth', 'meop_mld']]))\n",
    "    df.reset_index(inplace = True), \n",
    "    df[df.lstm < 5] = np.nan\n",
    "    df = df[df.FOD == fod]\n",
    "    FOD_df = pd.concat((FOD_df, df))\n",
    "    sns.kdeplot(df, x = 'lstm', y='mld_variation', ax = ax[fod-1])\n",
    "    sns.regplot(df, x = 'lstm', y='mld_variation', scatter = False, lowess = True, ax = ax[fod-1])\n",
    "    #sns.regplot(df, x = 'LSTM', y='mld_variation', scatter = False, order = 2, ax = ax[fod-1])\n",
    "    ax[fod-1].grid()\n",
    "    ax[fod-1].set_xlabel('')\n",
    "    ax[fod-1].set_ylabel('')\n",
    "    ax[fod-1].set_ylim(-100, 200)\n",
    "    ax[fod-1].set_title(f\"FOD {fod}\")\n",
    "fig.text(0.56, 0.04, 'Wind speed (m/s)', ha='center', va='center', fontsize=14)\n",
    "fig.text(0.04, 0.55, 'MLD variation (m)', ha='center', va='center', rotation='vertical', fontsize=14)\n",
    "fig.tight_layout(rect=[0.05, 0.05, 1, 1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "063cb659-23bb-4928-a9d6-e7bacbb6f3d5",
   "metadata": {},
   "source": [
    "fig.savefig('C:/Users/grosm/Desktop/thèse/Figures/wind_impact_on_mld.pdf')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e3a6393-28b9-4e54-b548-7c5fd2408443",
   "metadata": {},
   "source": [
    "### GLOBAL MLD VARIATION AFTER CHOSEN TIME LAG\n",
    "fig, ax = plt.subplots(1,1, figsize = (10, 10))\n",
    "df = pd.DataFrame()\n",
    "for j, depid in enumerate(depids_with_mld) :\n",
    "    _df = get_corr_df(depids, depid, path, data = 'downwards_mean_5000', i = 15)\n",
    "    df = pd.concat((df, _df[['mld_variation', 'lstm_15h', 'max_depth', 'meop_mld']]))\n",
    "df = df.reset_index()\n",
    "ax.set_title('MLD variation after 15 hours and initial MLD')\n",
    "ax.scatter(df.meop_mld, df.mld_variation,\n",
    "                  color=\"orange\", alpha=0.1)\n",
    "ax.plot(np.linspace(0, 400, 100), 0.97*np.linspace(0, 400, 100) - 10.67, c = 'red')\n",
    "ax.set_xlabel('MLD (m)')\n",
    "ax.set_ylabel('MLD variation (m)')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "60d0f16b-f767-4113-b0d3-fcaf6d820898",
   "metadata": {},
   "source": [
    "fig.savefig('C:/Users/grosm/Desktop/thèse/Figures/mld_variation.pdf')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "477d61c9-9a24-4c3e-947d-95175daea24a",
   "metadata": {},
   "source": [
    "### Wind gust duration"
   ]
  },
  {
   "cell_type": "code",
   "id": "f0586e50-06d5-4fbd-a418-815a344d4dc7",
   "metadata": {},
   "source": [
    "from scipy.signal import find_peaks, medfilt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import generic_filter\n",
    "from scipy import odr\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.families import Gaussian\n",
    "import statsmodels.genmod.bayes_mixed_glm as bayes_mixed_glm\n",
    "from statsmodels.multivariate.pca import PCA\n",
    "def norm(x) :\n",
    "    return (x - np.nanmin(x)) / (np.nanmax(x) - np.nanmin(x))\n",
    "from Biologging_Toolkit.utils.inertial_utils import coa\n",
    "from Biologging_Toolkit.utils.format_utils import numpy_fill"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc12f197-e181-4ba2-b0b4-d49fd8571f56",
   "metadata": {},
   "source": [
    "def get_peaks(df, data = 'lstm', threshold = 10, time_diff = 15) :\n",
    "    data = df[data].to_numpy()\n",
    "    timeframe = df.begin_time.to_numpy()\n",
    "    transition = np.diff((numpy_fill(data) >= threshold).astype(int))\n",
    "    first_peak = np.where((transition == 1))[0][0]\n",
    "    transition[:first_peak] = 0\n",
    "    left_base = np.where((transition == 1))[0]\n",
    "    right_base = np.where((transition == -1))[0]\n",
    "    bases = np.column_stack((left_base[:np.min((len(left_base), len(right_base)))], right_base[:np.min((len(left_base), len(right_base)))]))\n",
    "    wind_max, wind_mean, duration, peaks = [], [], [], []\n",
    "    for base in bases :\n",
    "        if base[1] - base[0] < 2:\n",
    "            continue\n",
    "        peaks.append(base[0] + np.argmax(np.nan_to_num(data[base[0]:base[1]])))\n",
    "        wind_max.append(np.nanmax(data[base[0]:base[1]]))\n",
    "        wind_mean.append(np.nanmean(data[base[0]:base[1]]))\n",
    "        duration.append(timeframe[base[1]] - timeframe[base[0]])\n",
    "    mld = df.meop_mld.to_numpy()\n",
    "    temp = df.temp_10m.to_numpy()\n",
    "    gradient = df.gradient.to_numpy()\n",
    "    mld_data = []\n",
    "    temp_data = []\n",
    "    gradient_data = []\n",
    "    for peak in peaks :\n",
    "        gradient_data.append(gradient[peak])\n",
    "        _mld = [mld[peak]]\n",
    "        _temp = [temp[peak]]\n",
    "        j = 0\n",
    "        while (peak+j < len(timeframe)) and (timeframe[peak + j] - timeframe[peak] < time_diff * 3600)  :\n",
    "            _mld.append(mld[peak + j])\n",
    "            _temp.append(temp[peak + j])\n",
    "            j+=1\n",
    "        mld_data.append(_mld)\n",
    "        temp_data.append(_temp)\n",
    "    return np.array(wind_max), np.array(wind_mean), np.array(duration), mld_data, temp_data, np.array(gradient_data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "38cbca9a-8c4c-4976-86cf-267becd4db23",
   "metadata": {},
   "source": [
    "def get_wind_gust(df, data = 'lstm', time_diff = 15) :\n",
    "    peaks, _ = find_peaks(df[data].to_numpy(), prominence = 1.5, height = 6, distance = 15)\n",
    "    timeframe = df.begin_time.to_numpy()\n",
    "    begin_gust, end_gust = timeframe[_['left_bases']], timeframe[_['right_bases']]\n",
    "    duration = end_gust - begin_gust\n",
    "    max_speed = df[data].to_numpy()[peaks]\n",
    "    temp20 = df['temp_20m'].to_numpy()[peaks]\n",
    "    temp10 = df['temp_10m'].to_numpy()[peaks]\n",
    "    average = []\n",
    "    for lb, rb in zip(_['left_bases'], _['right_bases']):\n",
    "        average.append(np.nanmean(df[data].to_numpy()[lb:rb+1]))\n",
    "    mld = df.meop_mld.to_numpy()\n",
    "    temp = df.temp_10m.to_numpy()\n",
    "    gradient = df.gradient.to_numpy()\n",
    "    mld_data = []\n",
    "    temp_data = []\n",
    "    other_peaks = []\n",
    "    gradient_data = []\n",
    "    for peak in peaks :\n",
    "        _other_peak = [np.nan]\n",
    "        _mld = [mld[peak]]\n",
    "        _temp = [temp[peak]]\n",
    "        gradient_data.append(gradient[peak])\n",
    "        j = 0\n",
    "        while (peak+j < len(timeframe)) and (timeframe[peak + j] - timeframe[peak] < time_diff * 3600)  :\n",
    "            _mld.append(mld[peak + j])\n",
    "            _temp.append(mld[peak + j])\n",
    "            if (peak+j>peak) and (peak+j in peaks) :\n",
    "                _other_peak.append(df[data].to_numpy()[peak+j])\n",
    "            j+=1\n",
    "        other_peaks.append(len(_other_peak))\n",
    "        mld_data.append(_mld)\n",
    "        temp_data.append(_temp)\n",
    "    return max_speed, np.array(average), duration, mld_data, np.array(other_peaks), temp_data, np.array(gradient_data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "724d7c11-6fdd-4e18-9c2f-4e1b730d07a3",
   "metadata": {},
   "source": [
    "_df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "data = _df['lstm'].to_numpy()\n",
    "timeframe = _df.begin_time.to_numpy()\n",
    "transition = np.diff((numpy_fill(data) >= 10).astype(int))\n",
    "first_peak = np.where((transition == 1))[0][0]\n",
    "transition[:first_peak] = 0\n",
    "left_base = np.where((transition == 1))[0]\n",
    "right_base = np.where((transition == -1))[0]\n",
    "bases = np.column_stack((left_base[:np.min((len(left_base), len(right_base)))], right_base[:np.min((len(left_base), len(right_base)))]))\n",
    "wind_max, wind_mean, duration, peaks = [], [], [], []\n",
    "for base in bases :\n",
    "    if base[1] - base[0] < 2:\n",
    "        continue\n",
    "    peaks.append(base[0] + np.argmax(np.nan_to_num(data[base[0]:base[1]])))\n",
    "\n",
    "peaks, _ = find_peaks(data, prominence = 1.5, height = 6, distance = 10)\n",
    "left_base, right_base = _['left_bases'], _['right_bases']\n",
    "bases = np.column_stack((left_base[:np.min((len(left_base), len(right_base)))], right_base[:np.min((len(left_base), len(right_base)))]))\n",
    "fig, ax = plt.subplots(figsize = (15,6))\n",
    "ax.plot(timeframe, data)\n",
    "ax.scatter(timeframe[peaks], data[peaks], c = 'orange', s = 25)\n",
    "for base in bases :\n",
    "    ax.plot([timeframe[base[0]], timeframe[base[1]]], [10,10], '--o', c = 'red')\n",
    "ax.set_xlim(timeframe[0], timeframe[500])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "intercept, peaks_coef, duration_coef, p_values, peaks_pval, duration_pval, r_squared, adj_r_squared = [],[],[],[],[],[],[],[]\n",
    "average_coef, average_pval, pmld_coef, pmld_pval = [],[],[],[]\n",
    "temp_coef, temp_pval, gradient_coef, gradient_pval = [], [], [], []\n",
    "intercept_se, peaks_se, duration_se = [], [], []\n",
    "r_squared_peaks, r_squared_duration = [], []\n",
    "\n",
    "params = ['peaks', 'duration', 'gradient', 'previous_mld', 'const']\n",
    "res_values = {par:[[],[]] for par in params}\n",
    "for j in np.arange(1,48,0.5) :\n",
    "    all_mld = []\n",
    "    all_temp = []\n",
    "    temp_var = []\n",
    "    mld_var = []\n",
    "    df = pd.DataFrame()\n",
    "    for i, depid in enumerate(depids_with_mld) :\n",
    "        _df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "        peaks, average, duration, mld_data, other_peaks, temp_data, gradient = get_wind_gust(_df, time_diff = j)\n",
    "        #peaks, average, duration, mld_data, temp_data, gradient = get_peaks(_df, time_diff = j)\n",
    "        mld, previous_mld = [_mld_data[-1] for _mld_data in mld_data], [_mld_data[0] for _mld_data in mld_data]\n",
    "        temp = [_temp_data[0] for _temp_data in temp_data]\n",
    "        _df = pd.DataFrame({'peaks':peaks,\n",
    "                                          'duration':duration,\n",
    "                                          'mld':mld,\n",
    "                                          'previous_mld':previous_mld,\n",
    "                                          'average':average,\n",
    "                                          'temp10': temp,\n",
    "                                          'gradient':gradient})\n",
    "        _df = _df.dropna(subset=params[:-1]+['mld'])\n",
    "        all_mld.extend([_mld_data for i,_mld_data in enumerate(mld_data) if i in _df.index])\n",
    "        all_temp.extend([_temp_data for i,_temp_data in enumerate(temp_data) if i in _df.index])\n",
    "        temp_var.extend([np.nanvar(_temp_data) for i,_temp_data in enumerate(temp_data) if i in _df.index])\n",
    "        mld_var.extend([np.nanvar(_mld_data) for i,_mld_data in enumerate(mld_data) if i in _df.index])\n",
    "        df = pd.concat((df, _df))\n",
    "    df['var_temp'] = temp_var\n",
    "    df['var_mld'] = mld_var\n",
    "\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    df = df[df.var_mld < 5000]\n",
    "    df['mld_diff'] = df['mld'] - df['previous_mld']\n",
    "    df = df[df.mld_diff > 0]\n",
    "\n",
    "    X = df[params[:-1]]\n",
    "    X = sm.add_constant(X)\n",
    "    y = df['mld']\n",
    "\n",
    "    model = sm.OLS(y, X)\n",
    "    #model = bayes_mixed_glm.BinomialBayesMixedGLM(y, X)\n",
    "    #data = odr.Data(df.peaks.to_numpy(), df.mld.to_numpy())\n",
    "    #odr_obj = odr.ODR(data, odr.quadratic)\n",
    "    #output = odr_obj.run()\n",
    "    results = model.fit()\n",
    "\n",
    "    for val in results.params.keys() :\n",
    "        res_values[val][0].append(results.params[val])\n",
    "        res_values[val][1].append(results.pvalues[val])\n",
    "    r_squared.append(results.rsquared)\n",
    "for val in results.params.keys() :\n",
    "    res_values[val] = np.array(res_values[val])"
   ],
   "id": "ab1c6f1c-7ed7-4ec1-87cb-ba2ad98b69f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fc13761-0b76-4763-9682-f18d7d1cdf6e",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax = ax.flatten()\n",
    "\n",
    "scat = ax[0].scatter(df.peaks.to_numpy(), df.mld.to_numpy(), c=df.var_mld.to_numpy())\n",
    "fig.colorbar(scat, ax=ax[0])\n",
    "ax[0].set_title(\"Variance MLD\")\n",
    "scat = ax[1].scatter(df.peaks.to_numpy(), df.mld.to_numpy(), c=df.gradient.to_numpy())\n",
    "fig.colorbar(scat, ax=ax[1])\n",
    "ax[1].set_title(\"Variance 10m Temperature\")\n",
    "mask = (df.temp10.to_numpy() < 50) & (df.var_temp < 15500)\n",
    "scat = ax[2].scatter(df.peaks.to_numpy()[mask], df.mld.to_numpy()[mask], c=df.temp10.to_numpy()[mask], alpha=0.9)\n",
    "fig.colorbar(scat, ax=ax[2])\n",
    "sns.kdeplot(df[mask], x='peaks', y='mld', ax=ax[2], alpha = 0.7)\n",
    "ax[2].set_title(r\"10m Temperature at $t_0$\")\n",
    "mask = (df.temp10.to_numpy() <= 50) & (df.var_mld < 15400)\n",
    "scat = ax[3].scatter(df.peaks.to_numpy()[mask], df.mld.to_numpy()[mask], c=df.duration.to_numpy()[mask])\n",
    "fig.colorbar(scat, ax=ax[3])\n",
    "ax[3].set_title(\"Wind gust duration\")\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xlabel(\"\")\n",
    "    a.set_ylabel(\"\")\n",
    "fig.text(0.5, 0.0, \"Wind Speed (m/s)\", ha=\"center\", fontsize=12)\n",
    "fig.text(0.0, 0.5, \"MLD (m)\", va=\"center\", rotation=\"vertical\", fontsize=12)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f740c87-e180-4dc6-b3fe-42bd615ee063",
   "metadata": {},
   "source": [
    "### PLOT COEFFICIENTS, R2, PVALUES AND MODEL PREDICTION AS A FUNCTION OF TIME LAG\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax = ax.flatten()\n",
    "colors = ['blue', 'red', 'fuchsia', 'gold', 'green']\n",
    "markers = ['o','p','s','x']\n",
    "labels = {'peaks':'Maximum wind speed', 'duration':'Wind gust duration', 'previous_mld':'Previous MLD', 'gradient':'Density gradient at MLD', 'temp10':'Temperature at 10m'}\n",
    "\n",
    "lines = []\n",
    "ax1 = ax[0].twinx()\n",
    "for i, val in enumerate(res_values.keys()) :\n",
    "    if val == 'const':\n",
    "        continue\n",
    "    if val == 'gradient' :\n",
    "        line = ax1.plot(res_values[val][0], colors[i], marker = markers[i], label = labels[val], markevery = 2)\n",
    "        ax1.set_ylabel('Gradient coefficient', color=colors[i])\n",
    "        ax1.tick_params(axis='y', labelcolor=colors[i])\n",
    "        lines.extend(line)\n",
    "        continue\n",
    "    line = ax[0].plot(res_values[val][0], colors[i], marker = markers[i], label = labels[val], markevery = 2)\n",
    "    lines.extend(line)\n",
    "\n",
    "ax0_labels = [l.get_label() for l in lines]\n",
    "ax[0].legend(lines, ax0_labels, loc='upper left')\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel('Time differential between wind gust and MLD (h)')\n",
    "ax[0].set_title('Linear regression coefficients')\n",
    "\n",
    "ax[1].plot(r_squared, color='green', label=r'Global $R^2$', marker='^')\n",
    "#np.argmax(r_squared)\n",
    "ax[1].plot([13]*2, [0, r_squared[13]], '--', c = 'k')\n",
    "ax[1].set_ylabel(r'$R^2$')\n",
    "ax[1].set_xlabel('Time differential between wind gust and MLD (h)')\n",
    "ax[1].legend()\n",
    "ax[1].set_title(r'$R^2$ between dependant variables and $\\Delta$MLD')\n",
    "ax[1].grid()\n",
    "\n",
    "lines = []\n",
    "for i, val in enumerate(res_values.keys()) :\n",
    "    if val == 'const':\n",
    "        continue\n",
    "    line = ax[2].plot(res_values[val][1], colors[i], marker = markers[i], label = labels[val], markevery = 2)\n",
    "    lines.extend(line)\n",
    "\n",
    "ax[2].set_xlabel('Time differential between wind gust and MLD (h)')\n",
    "ax[2].set_title('P-values for wind gust speed and duration')\n",
    "ax[2].grid()\n",
    "\n",
    "plot_df = pd.DataFrame()\n",
    "for i, depid in enumerate(depids_with_mld) :\n",
    "    _plot_df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "    #np.argmax(r_squared)\n",
    "    peaks, average, duration, mld_data, temp_data, gradient = get_peaks(_plot_df, time_diff = 13)\n",
    "    #peaks, average, duration, mld_data, other_peaks, temp_data = get_wind_gust(_plot_df, time_diff = 14)\n",
    "    mld, previous_mld = [_mld_data[-1] for _mld_data in mld_data], [_mld_data[0] for _mld_data in mld_data]\n",
    "    temp = [_temp_data[0] for _temp_data in temp_data]\n",
    "    plot_df = pd.concat((plot_df, pd.DataFrame({'peaks':peaks, \n",
    "                                      'duration':duration, \n",
    "                                      'mld':mld, \n",
    "                                      'previous_mld':previous_mld,\n",
    "                                      'average':average,\n",
    "                                      'temp10':temp,\n",
    "                                      'gradient':gradient})))\n",
    "plot_df.reset_index(inplace = True)\n",
    "plot_df['pred'] = np.array([res_values[val][0,13]*plot_df[val].to_numpy() for val in list(res_values.keys())[:-1]]).sum(axis = 0) + res_values['const'][0,13]\n",
    "sns.kdeplot(plot_df, x = 'mld', y = 'pred', ax=ax[3])\n",
    "ax[3].scatter(plot_df.mld, plot_df.pred, alpha = 0.2, c = 'royalblue')\n",
    "ax[3].plot([-40,400], [-40,400], '--' , c='k')\n",
    "ax[3].grid()\n",
    "ax[3].set_title(r\"Model's prediction for 13h lag\")\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1b788e93",
   "metadata": {},
   "source": [
    "fig.savefig('C:/Users/grosm/Desktop/thèse/Figures/OLS1_peaks_duration_pmld_average.pdf')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "43045546-8058-42b7-9670-88894a3eb28c",
   "metadata": {},
   "source": [
    "### GET FINAL LAW DESCRIBING BEHAVIOR\n",
    "plt.rc('text', usetex=True)\n",
    "nmax = 72\n",
    "ninter = 14\n",
    "fit_func = lambda x, a, b : a*x+b\n",
    "ppeaks1, _ = curve_fit(fit_func, list(range(0, ninter)), peaks_coef[:ninter], nan_policy = 'omit')\n",
    "ppeaks2, _ = curve_fit(fit_func, list(range(ninter,nmax)), peaks_coef[ninter:nmax], nan_policy = 'omit')\n",
    "pinter, _ = curve_fit(fit_func, list(range(0, nmax)), intercept[:nmax], nan_policy = 'omit')\n",
    "#pdur, _ = curve_fit(fit_func, list(range(0, nmax)), duration_coef[:nmax], nan_policy = 'omit')\n",
    "ppeaks = [ppeaks1]*ninter\n",
    "ppeaks.extend([ppeaks2]*(nmax-ninter))\n",
    "              \n",
    "fig, ax = subplots_centered(2,2, nfigs = 3, figsize = (10,8))\n",
    "ax1 = ax[0].twinx()\n",
    "ax1.scatter(list(range(0,nmax)), peaks_coef[:nmax], label = 'Maximum wind speed')\n",
    "line1 = ax1.plot(list(range(0,nmax)), fit_func(np.array(list(range(0,nmax))), *ppeaks1), '--', c = 'blue', label = 'Maximum wind speed')\n",
    "ax1.set_ylabel('Speed coefficient', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.plot(list(range(0,nmax)), fit_func(np.array(list(range(0,nmax))), *ppeaks2), '--', c = 'blue')\n",
    "#ax[0].scatter(list(range(0,nmax)), duration_coef, c = 'fuchsia', label = 'Duration')\n",
    "#ax[0].plot(list(range(0,nmax)), fit_func(np.array(list(range(0,nmax))), *pdur[:nmax]), '--', c = 'fuchsia')\n",
    "ax[0].scatter(list(range(0,nmax)), intercept[:nmax], c  = 'orange')\n",
    "line2 = ax[0].plot(list(range(0,nmax)), fit_func(np.array(list(range(0,nmax))), *pinter[:nmax]), '--', c = 'orange', label = 'Intercept')\n",
    "ax[0].grid()\n",
    "ax[0].set_ylabel('Intercept value', color='orange')\n",
    "ax[0].tick_params(axis='y', labelcolor='orange')\n",
    "lines = line1 +line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper left')\n",
    "ax[0].set_title('Model parameters as a function of time')\n",
    "ax[0].set_xlabel('Time (h)')\n",
    "ax[0].set_ylabel('Parameter values')\n",
    "\n",
    "graph_i = ninter\n",
    "for i in range(1,nmax-1) :\n",
    "    plot_df = pd.DataFrame()\n",
    "    for j, depid in enumerate(depids_with_mld) :\n",
    "        _plot_df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "        #np.argmax(r_squared)\n",
    "        peaks, average, duration, mld_data, other_peaks, temp_data = get_wind_gust(_plot_df, time_diff = i)\n",
    "        mld, previous_mld = [_mld_data[-1] for _mld_data in mld_data], [_mld_data[0] for _mld_data in mld_data]\n",
    "        temp = [_temp_data[0] for _temp_data in temp_data]\n",
    "        plot_df = pd.concat((plot_df, pd.DataFrame({'peaks':peaks, \n",
    "                                          'duration':duration, \n",
    "                                          'mld':mld, \n",
    "                                          'previous_mld':previous_mld,\n",
    "                                          'temp10':temp})))\n",
    "    if graph_i == i:\n",
    "        graph_df = plot_df\n",
    "    err = ax[1].scatter(i, np.nanmean(abs(plot_df.mld.to_numpy() \n",
    "                                       - ((ppeaks[i][0]*i + ppeaks[i][1])*plot_df.peaks.to_numpy()\n",
    "                                       + pinter[0]*i + pinter[1]))),\n",
    "                                       #+ (pdur[0]*i + pdur[1])*plot_df.duration.to_numpy()))),\n",
    "                        c = 'red')\n",
    "ax[1].legend([err], ['MLD estimation mean absolute error'])\n",
    "ax[1].set_ylabel('Error (m)')\n",
    "ax[1].set_xlabel('Time (h)')\n",
    "ax[1].set_title('Error as a function of time')\n",
    "\n",
    "scat = ax[2].scatter(graph_df.mld, (ppeaks[graph_i][0]*graph_i + ppeaks[graph_i][1])*graph_df.peaks.to_numpy() + pinter[0]*graph_i + pinter[1], c = graph_df.temp10) #+ plot_df.previous_mld.to_numpy()) \n",
    "ax[2].plot([0,400], [0,400], '--')\n",
    "ax[2].set_xlabel('MLD')\n",
    "ax[2].set_ylabel('Prediction')\n",
    "fig.colorbar(scat, ax=ax[2])\n",
    "ax[2].set_title(\"Prediction with 10m Temperature colorbar\")\n",
    "fig.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b05c8ba-cea3-4c6d-bc41-9933d607b67a",
   "metadata": {},
   "source": [
    "fig.savefig('C:/Users/grosm/Desktop/thèse/Figures/model_parameters_and_error.pdf')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "04425929-cdd7-4fe8-845d-e11b778a9992",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "###### USING CURVE FIT\n",
    "mae = []\n",
    "params = []\n",
    "def f(X,a,b,c):\n",
    "    x,y = X\n",
    "    return a*x+b*y+c\n",
    "def g(x, a, b, c) :\n",
    "    return a*x**2 + b*x + c\n",
    "bounds = [[0,-np.inf, 0],[np.inf, np.inf, 50]]\n",
    "for j in range(1, 73) :\n",
    "    all_mld = []\n",
    "    all_temp = []\n",
    "    all_var = []\n",
    "    df = pd.DataFrame()\n",
    "    for i, depid in enumerate(depids_with_mld) :\n",
    "        _df = pd.read_csv(os.path.join(path, depid, f'{depid}_dive.csv'))\n",
    "        peaks, average, duration, mld_data, other_peaks, temp_data = get_wind_gust(_df, time_diff = j)\n",
    "        mld, previous_mld = [_mld_data[0] for _mld_data in mld_data], [_mld_data[-1] for _mld_data in mld_data]\n",
    "        temp = [_temp_data[0] for _temp_data in temp_data]\n",
    "        _df = pd.DataFrame({'peaks':peaks, \n",
    "                                    'mld':mld, \n",
    "                                    'previous_mld':previous_mld,\n",
    "                                    'temp10':temp})\n",
    "        _df = _df.dropna(subset=['peaks', 'mld'])\n",
    "        all_mld.extend([_mld_data for i,_mld_data in enumerate(mld_data) if i in _df.index])\n",
    "        all_temp.extend([_temp_data for i,_temp_data in enumerate(temp_data) if i in _df.index])\n",
    "        all_var.extend([np.nanvar(_temp_data) for i,_temp_data in enumerate(temp_data) if i in _df.index])\n",
    "        df = pd.concat((df, _df))\n",
    "    df['var_temp'] = all_var\n",
    "    df.reset_index(inplace = True, drop = True)\n",
    "    df = df[df.var_temp < 1500]\n",
    "    df['mld_diff'] = df['mld'] - df['previous_mld']\n",
    "    df = df[df.temp10.to_numpy() < 7.5]\n",
    "    popt_, _ = curve_fit(g, df.peaks.to_numpy(), df.mld.to_numpy(), bounds = bounds)\n",
    "    mae.append(np.mean(abs(df.mld.to_numpy() - g(df.peaks.to_numpy(), *popt_))))\n",
    "    params.append(popt_)\n",
    "\n",
    "params = np.array(params)\n",
    "fig, ax = plt.subplots(1,3, figsize = (20,8))\n",
    "ax[2].scatter(df.peaks.to_numpy(), df.mld.to_numpy())\n",
    "ax[2].plot(list(range(0,20)), g(np.array(list(range(0,20))), *params[20]))\n",
    "ax[0].plot(mae)\n",
    "ax[1].plot(params[:,0])\n",
    "ax[1].plot(params[:,1])\n",
    "#ax[1].plot(params[:,2])\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "911a699c-33a1-436a-8e24-ed9ab716688f",
   "metadata": {},
   "source": [
    "### FOR LAST TIME STEP, SHOW MLD VARIATION AS A FUNCTION OF WIND SPEED AND DEPTH\n",
    "temp_df = df[(df.mld > df.previous_mld) & (df.mld - df.previous_mld < df.mld * 0.5)]\n",
    "wind_bins = np.arange(0, 21, 0.5)  \n",
    "depth_bins = np.arange(0, 250, 10)  \n",
    "temp_df[\"wind_bin\"] = pd.cut(temp_df[\"peaks\"], bins=wind_bins, labels=wind_bins[:-1])\n",
    "temp_df[\"depth_bin\"] = pd.cut(temp_df[\"previous_mld\"], bins=depth_bins, labels=depth_bins[:-1])\n",
    "\n",
    "binned_data = (temp_df.groupby([\"wind_bin\", \"depth_bin\"])[\"mld_diff\"].mean().reset_index().dropna())\n",
    "binned_data[\"wind_bin\"] = binned_data[\"wind_bin\"].astype(float)\n",
    "binned_data[\"depth_bin\"] = binned_data[\"depth_bin\"].astype(float)\n",
    "\n",
    "wind_grid = wind_bins[:-1]\n",
    "depth_grid = depth_bins[:-1]\n",
    "data_2d = np.full((len(depth_grid), len(wind_grid)), np.nan)\n",
    "\n",
    "for _, row in binned_data.iterrows():\n",
    "    wind_idx = np.where(wind_grid == row[\"wind_bin\"])[0][0]\n",
    "    depth_idx = np.where(depth_grid == row[\"depth_bin\"])[0][0]\n",
    "    data_2d[depth_idx, wind_idx] = row[\"mld_diff\"]\n",
    "def nanmean_kernel(values):\n",
    "    return np.nanmean(values)\n",
    "filtered_data_2d = generic_filter(data_2d, nanmean_kernel, size=5, mode='constant', cval=np.nan)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "wind_bin_centers = (wind_bins[:-1] + wind_bins[1:]) / 2\n",
    "depth_bin_centers = (depth_bins[:-1] + depth_bins[1:]) / 2\n",
    "X, Y = np.meshgrid(wind_bin_centers, depth_bin_centers)\n",
    "scatter = ax.scatter(X.flatten(), Y.flatten(), c=filtered_data_2d.flatten(), s=50, cmap=\"viridis\")\n",
    "#scatter = ax.imshow(filtered_data_2d, aspect = 'auto', origin = 'lower')\n",
    "cbar = fig.colorbar(scatter, ax=ax, label=\"MLD variation (m)\")\n",
    "ax.set_xlabel(\"Wind Speed (m/s)\")\n",
    "ax.set_ylabel(\"Depth (m)\")\n",
    "ax.set_title(\"MLD Variation as a function of wind speed\")\n",
    "#plt.gca().invert_yaxis()\n",
    "ax.grid(True)\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8f176020",
   "metadata": {},
   "source": [
    "### PCA FOR INDEPENDANT VARIABLES\n",
    "\n",
    "pca_model = PCA(df, ncomp=4, standardize=True, method='eig')  # Standardized PCA\n",
    "factors = pca_model.factors.to_numpy()  # Principal components (scores)\n",
    "loadings = pca_model.loadings.to_numpy()  # Loadings (eigenvectors)\n",
    "explained_variance = pca_model.eigenvals / np.sum(pca_model.eigenvals)  # Proportion of variance explained\n",
    "\n",
    "# 2.1 Scree Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', linestyle='--', color='b')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.show()\n",
    "\n",
    "# 2.2 Score Plot (PC1 vs. PC2)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(factors[:, 0], factors[:, 1], alpha=0.7, edgecolors='k', label='Scores')\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.axvline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.title('Score Plot (PC1 vs. PC2)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2.3 Loading Plot (PC1 vs. PC2)\n",
    "plt.figure(figsize=(8, 5))\n",
    "for i, var in enumerate(df.columns):\n",
    "    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], color='r', alpha=0.8, head_width=0.05)\n",
    "    plt.text(loadings[i, 0] * 1.2, loadings[i, 1] * 1.2, var, color='g', ha='center', va='center')\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.axvline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.title('Loading Plot (PC1 vs. PC2)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 2.4 Biplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(factors[:, 0], factors[:, 1], alpha=0.7, edgecolors='k', label='Scores')\n",
    "for i, var in enumerate(df.columns):\n",
    "    plt.arrow(0, 0, loadings[i, 0], loadings[i, 1], color='r', alpha=0.8, head_width=0.05)\n",
    "    plt.text(loadings[i, 0] * 1.2, loadings[i, 1] * 1.2, var, color='g', ha='center', va='center')\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.axvline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "plt.title('Biplot (Scores and Loadings)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 2.5 Cumulative Variance Explained Plot\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--', color='g')\n",
    "plt.title('Cumulative Variance Explained')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Proportion of Variance Explained')\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='90% Variance Explained')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f6ba90c-17d0-449d-8a3e-091dee8684e1",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize = (7,7))\n",
    "df['init_mld'] = df.previous_mld < 30\n",
    "sns.kdeplot(df, x='peaks', y='mld', hue = 'init_mld', ax = ax)\n",
    "ax.set_ylim(-10, 400)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a51804f-8fc5-496a-b350-f0b4e1402866",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
